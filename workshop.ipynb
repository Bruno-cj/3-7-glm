{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Binary Classification\n",
    "\n",
    "### 1.1 Titanic, but correctly this time\n",
    "\n",
    "Take your linear regression model from the workshop 3.3 on the titanic dataset.\n",
    "\n",
    "Swap OLS for logistic regresssion and compare the classification model metrics (accuracy, ROC plot, F1, precision/recall).\n",
    "\n",
    "How much better is logistic regression than OLS on binary data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Intro To Computer Vision\n",
    "\n",
    "The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is a classic in computer vision. It's a database of manually written digits (from 0 to 9) scanned into a 28x28 pixel image.\n",
    "\n",
    "The `X` matrix is 784 numbers (28x28) with numbers saying how dark the pixel is. The `y` variable is the number. The task is to use the images to do optical recognition.\n",
    "\n",
    "You can fetch the dataset with the following command:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import fetch_openml\n",
    "fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "```\n",
    "\n",
    "Use sklearn's logistic regression and any of the tricks you want to boost predictive accuracy. Here's a few notes:\n",
    "\n",
    "- Use the sklearn `train_test_split` we saw in class to keep some holdout data to test on.\n",
    "\n",
    "- You can use whatever sklearn preprocessing you think is relevant. Here's a few: \n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "```\n",
    "\n",
    "- Since there's many features (especially if you use data augmentation like polynomial features), this is a good time to use regularization. Try to find the best regularization parameters possible.\n",
    "\n",
    "- You should be able to get at least 80% on a test set size of 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Counting Poissons\n",
    "\n",
    "The `data/fish.csv` is a data set of camping trips taken by 250 groups of people.\n",
    "\n",
    "- The campers may or may not have done some fishing during their trip.\n",
    "- If a group did some fishing, they would have caught zero or mor fish.\n",
    "- We want to estimate not only how many fish were caught (if there was fishing done by a camping group), but also the probability that the camping group caught any fish at all.\n",
    "\n",
    "Here's info on the columns:\n",
    "\n",
    "**FISH_COUNT:** The number of fish that were caught. This will be our dependent variable y.\n",
    "\n",
    "**LIVE_BAIT:** A binary variable indicating whether live bait was used.\n",
    "\n",
    "**CAMPER:** Whether the fishing group used a camper van.\n",
    "\n",
    "**PERSONS:** Total number of people in the fishing group. Note that in some groups, none of them may have fished.\n",
    "\n",
    "**CHILDREN:** The number of children in the camping group.\n",
    "\n",
    "Your task is to predict the number of fish caught (FISH_COUNT) by a camping group based on the values of LIVE_BAIT, CAMPER, PERSONS and CHILDREN variables.\n",
    "\n",
    "Use what we learned on count variables and zero-inflated datasets to achieve the best model you can.\n",
    "\n",
    "Interpret the models you used to give an analysis of each feature's effect on the predicted fish caught.\n",
    "\n",
    "**N.B.** Please appreciate the effort I went through to find a fish dataset for a count problem pun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Survival Question\n",
    "\n",
    "The `data/telco_churn.csv` dataset comes from [here](https://www.kaggle.com/blastchar/telco-customer-churn) and here is the description:\n",
    "\n",
    "**Context**\n",
    "\n",
    "\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n",
    "Content\n",
    "\n",
    "Each row represents a customer, each column contains customer’s attributes described on the column Metadata.\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "- Customers who left within the last month – the column is called Churn\n",
    "- Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "- Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "- Demographic info about customers – gender, age range, and if they have partners and dependents\n",
    "\n",
    "\n",
    "**5.1 StreamingTV churn**\n",
    "\n",
    "The `Tenure` column is how long the customer lasted. Make the survival curve for both the group using StreamingTV and the one not using it in the dataset\n",
    "\n",
    "![](streamingtv.png)\n",
    "\n",
    "\n",
    "**5.2 Survival Regression**\n",
    "\n",
    "Use either lifelines or statsmodels to implement a survival regression model predicting tenure. Don't forget to use the churn column as the event column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}